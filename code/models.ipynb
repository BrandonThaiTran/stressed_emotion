{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "material-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sampler\n",
    "import datasets\n",
    "from earlystopping import EarlyStopping\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from torch.autograd  import  Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-farmer",
   "metadata": {},
   "source": [
    "# Acoustic Branch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-basement",
   "metadata": {},
   "source": [
    "Inputs for acoustic branch will be N x 40 where N [1,33]  \n",
    "Time step: (2, 10) (seconds?)  \n",
    "N: relative duration after feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nominated-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcousticNet(nn.Module):\n",
    "    def __init__(self, num_conv_layers = 3, kernel_size = 2, conv_width = 32, num_gru_layers = 2):\n",
    "        super(AcousticNet, self).__init__()\n",
    "        self.num_conv_layers = num_conv_layers\n",
    "        self.conv1 = nn.Conv1d(in_channels=40, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=conv_width, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=conv_width, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=conv_width, out_channels=conv_width, kernel_size=kernel_size, padding = kernel_size - 1)\n",
    "        self.convs = [self.conv1, self.conv2, self.conv3, self.conv4]\n",
    "        self.max_pool = nn.MaxPool1d(kernel_size = 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.gru = nn.GRU(input_size=conv_width,hidden_size=32,num_layers=num_gru_layers) # 19 is hardcoded\n",
    "        self.mean_pool = nn.AvgPool1d(kernel_size=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.transpose(x, 1, 2) \n",
    "#         print(x.shape)\n",
    "        for i in range(self.num_conv_layers):\n",
    "            x = self.relu(self.max_pool(self.convs[i](x)))\n",
    "        x = torch.transpose(x, 1, 2) \n",
    "        x, _ = self.gru(x)\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = F.adaptive_avg_pool1d(x,1)[:, :, -1]\n",
    "#         x = self.mean_pool(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "charitable-belief",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output: torch.Size([8, 32])\n"
     ]
    }
   ],
   "source": [
    "# Test dummy input\n",
    "net = AcousticNet(num_conv_layers = 3, kernel_size = 2, conv_width = 32, num_gru_layers = 2)\n",
    "batch_size = 8\n",
    "n_acoustic_channels = 40\n",
    "duration_acoustic = 1232\n",
    "test_vec = torch.randn(batch_size, duration_acoustic, n_acoustic_channels) # samples x features (or channels) x N (relative duration)\n",
    "output = net(test_vec)\n",
    "print(f'Shape of output: {output.shape}')\n",
    "# assert output.shape[-1] == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "established-milwaukee",
   "metadata": {},
   "source": [
    "# Lexical Branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "duplicate-salmon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement GRU (or transformer)\n",
    "class LexicalNet(nn.Module):\n",
    "    def __init__(self, num_gru_layers = 2):\n",
    "        super(LexicalNet, self).__init__()\n",
    "        # implement GRU (or transformer)\n",
    "        self.gru = nn.GRU(input_size=768,hidden_size=32,num_layers=num_gru_layers)\n",
    "        self.mean_pool = nn.AvgPool1d(kernel_size=2) \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.gru(x)\n",
    "#         x = self.mean_pool(x)\n",
    "        x = self.flatten(x)\n",
    "#         print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amateur-tourism",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dummy input\n",
    "net = LexicalNet(num_gru_layers = 2)\n",
    "batch_size = 8\n",
    "test_vec = torch.randn(batch_size, 1, 768)\n",
    "output = net(test_vec)\n",
    "# assert output.shape[-1] == 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-induction",
   "metadata": {},
   "source": [
    "# Master branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "architectural-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GRL(Function):\n",
    "#     @staticmethod\n",
    "#     def forward(self,x):\n",
    "#         return x\n",
    "#     @staticmethod\n",
    "#     def backward(self,grad_output):\n",
    "#         grad_input = grad_output.neg()\n",
    "#         return grad_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inclusive-communication",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalFunction(Function):\n",
    "    \"\"\"\n",
    "    Gradient Reversal Layer from:\n",
    "    Unsupervised Domain Adaptation by Backpropagation (Ganin & Lempitsky, 2015)\n",
    "    Forward pass is the identity function. In the backward pass,\n",
    "    the upstream gradients are multiplied by -lambda (i.e. gradient is reversed)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, lambda_):\n",
    "        ctx.lambda_ = lambda_\n",
    "        return x.clone()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grads):\n",
    "        lambda_ = ctx.lambda_\n",
    "        lambda_ = grads.new_tensor(lambda_)\n",
    "        dx = -lambda_ * grads\n",
    "        return dx, None\n",
    "    \n",
    "class GradientReversal(torch.nn.Module):\n",
    "    def __init__(self, lambda_=1):\n",
    "        super(GradientReversal, self).__init__()\n",
    "        self.lambda_ = lambda_\n",
    "        print(self.lambda_)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return GradientReversalFunction.apply(x, self.lambda_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "enabling-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MasterNet(nn.Module):\n",
    "    def __init__(self, acoustic_modality = True, lexical_modality = True, visual_modality = False,\n",
    "                 num_conv_layers = 3, kernel_size = 2, conv_width = 32, num_gru_layers = 2,\n",
    "                 num_dense_layers = 1, dense_layer_width = 32, grl_lambda = .3):\n",
    "        super(MasterNet, self).__init__()\n",
    "        \n",
    "        self.acoustic_modality = acoustic_modality\n",
    "        self.lexical_modality = lexical_modality\n",
    "        self.visual_modality = visual_modality\n",
    "        \n",
    "        self.acoustic_model = AcousticNet(num_conv_layers = num_conv_layers, kernel_size = kernel_size, \n",
    "                                     conv_width = conv_width, num_gru_layers = num_gru_layers)\n",
    "        self.lexical_model = LexicalNet(num_gru_layers = 2)\n",
    "        \n",
    "        # emotion classifier\n",
    "#         self.dense1_emo = nn.Linear()\n",
    "#         self.dense2_emo = nn.Linear()\n",
    "        \n",
    "        width = 0 # width of the FC layers\n",
    "        if self.acoustic_modality:\n",
    "            width += 32\n",
    "        if self.visual_modality:\n",
    "            width += 0 # to implement\n",
    "        if self.lexical_modality:\n",
    "            width += 32\n",
    "            \n",
    "        self.fc_1 = nn.Linear(width, dense_layer_width)\n",
    "        self.fc_2 = nn.Linear(dense_layer_width, 3)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "#         # To implement   \n",
    "#         if num_dense_layers == 2:\n",
    "#             self.fc = nn.Sequential()\n",
    "#             self.linear_1 = nn.Linear(width, dense_layer_width)\n",
    "#         else:\n",
    "#             self.fc = \n",
    "        \n",
    "        # confound classifier -- to implement\n",
    "        self.grl = GradientReversal(lambda_ = grl_lambda)\n",
    "        self.dense_conv = nn.Linear(width, 2)\n",
    "#         self.dense2_con = None\n",
    "        \n",
    "        \n",
    "    def forward_a(self, x_a):\n",
    "        x = x_a\n",
    "        x = self.acoustic_model(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_l(self, x_l):\n",
    "        x = torch.unsqueeze(x_l, dim = 1)\n",
    "        x = self.lexical_model(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_v(self, x_v):\n",
    "        x = x_v\n",
    "        return x\n",
    "    \n",
    "    def encoder(self, x_v, x_a, x_l):\n",
    "        if self.visual_modality:\n",
    "            x_v = self.forward_v(x_v)\n",
    "        if self.acoustic_modality:\n",
    "            x_a = self.forward_a(x_a)\n",
    "        if self.lexical_modality:\n",
    "            x_l = self.forward_l(x_l)\n",
    "        \n",
    "        if self.visual_modality:\n",
    "            if self.acoustic_modality:\n",
    "                if self.lexical_modality:\n",
    "                    x = torch.cat((x_v, x_a, x_l), 1)\n",
    "                else:\n",
    "                    x = torch.cat((x_v, x_a), 1)\n",
    "            else:\n",
    "                if self.lexical_modality:\n",
    "                    x = torch.cat((x_v, x_l), 1)\n",
    "                else:\n",
    "                    x = x_v\n",
    "        else:\n",
    "            if self.acoustic_modality:\n",
    "                if self.lexical_modality:\n",
    "                    x = torch.cat((x_a, x_l), 1)\n",
    "                else:\n",
    "                    x = x_a\n",
    "            else:\n",
    "                x = x_l\n",
    "        return x\n",
    "\n",
    "    def confound_model(self, x):\n",
    "#         x = self.grl.apply(x)\n",
    "        x = self.grl(x)\n",
    "        x = self.dense_conv(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    # For emotion\n",
    "    def recognizer(self, x):\n",
    "#         print(x.shape)\n",
    "        x = self.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x_v, x_a, x_l):\n",
    "        x = self.encoder(x_v, x_a, x_l)\n",
    "        emotion_output = self.recognizer(x)\n",
    "        confound_output = self.confound_model(x)\n",
    "        \n",
    "        return emotion_output, confound_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "behind-cemetery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "Shape of emotion output: torch.Size([8, 3])\n",
      "Shape of stress output: torch.Size([8, 2])\n",
      "tensor([[0.3100, 0.3775, 0.3125],\n",
      "        [0.2985, 0.3870, 0.3145],\n",
      "        [0.2877, 0.3963, 0.3160],\n",
      "        [0.2791, 0.3976, 0.3232],\n",
      "        [0.2929, 0.3891, 0.3180],\n",
      "        [0.2906, 0.3920, 0.3174],\n",
      "        [0.2855, 0.3944, 0.3201],\n",
      "        [0.2957, 0.3854, 0.3189]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.5057, 0.4943],\n",
      "        [0.5140, 0.4860],\n",
      "        [0.5126, 0.4874],\n",
      "        [0.4961, 0.5039],\n",
      "        [0.4620, 0.5380],\n",
      "        [0.3938, 0.6062],\n",
      "        [0.3788, 0.6212],\n",
      "        [0.4160, 0.5840]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Test dummy input\n",
    "net = MasterNet()\n",
    "batch_size = 8\n",
    "n_acoustic_channels = 40\n",
    "duration_acoustic = 1232\n",
    "acoustic_features = torch.randn(batch_size, duration_acoustic, n_acoustic_channels) # samples x features (or channels) x N (relative duration)\n",
    "# lexical_features = torch.randn(batch_size, 1, 300)\n",
    "lexical_features = torch.randn(batch_size, 768)\n",
    "visual_features = None\n",
    "emotion_output, stress_output = net(visual_features, acoustic_features, lexical_features)\n",
    "print(f'Shape of emotion output: {emotion_output.shape}')\n",
    "print(f'Shape of stress output: {stress_output.shape}')\n",
    "print(emotion_output)\n",
    "print(stress_output)\n",
    "# assert output.shape[-1] == 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "introductory-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use specific GPU\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():  \n",
    "        dev = \"cuda:0\" \n",
    "    else:  \n",
    "        dev = \"cpu\"  \n",
    "    return torch.device(dev)\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "enhanced-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_folder(model, folder = 0, epochs = 1, verbose = False, learning_rate = 1e-4, patience = 5):\n",
    "    # Use specific GPU\n",
    "    device = get_device()\n",
    "\n",
    "    # Dataloaders    \n",
    "    train_dataset_file_path = '../dataset/IEMOCAP/' + str(folder) + '/train.csv'\n",
    "    train_loader = datasets.get_dataloader(train_dataset_file_path, 'train')\n",
    "    test_dataset_file_path = '../dataset/IEMOCAP/' + str(folder) + '/test.csv'\n",
    "    test_loader = datasets.get_dataloader(test_dataset_file_path, 'test')\n",
    "\n",
    "    # Model, optimizer and loss function\n",
    "    init_weights(model)\n",
    "    for param in emotion_recognizer.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    best_acc = 0.\n",
    "    best_uar = 0.\n",
    "    es = EarlyStopping(patience=patience)\n",
    "\n",
    "    # Train and validate\n",
    "    for epoch in range(epochs):\n",
    "        if verbose:\n",
    "            print('epoch: {}/{}'.format(epoch + 1, epochs))\n",
    "\n",
    "        train_loss, train_acc = train(train_loader, model,\n",
    "                                        optimizer, criterion, device)\n",
    "        test_loss, test_acc, test_uar = test(test_loader, model,\n",
    "                                                criterion, device)\n",
    "\n",
    "        if verbose:\n",
    "            print('train_emotion_loss: {0:.5f}'.format(train_loss['emotion_loss']),\n",
    "                  'train_emotion_acc: {0:.3f}'.format(train_acc['emotion_acc']),\n",
    "                  'train_confound_loss: {0:.5f}'.format(train_loss['confound_loss']),\n",
    "                  'train_confound_acc: {0:.3f}'.format(train_acc['confound_acc']),\n",
    "                  'test_emotion_loss: {0:.5f}'.format(test_loss['emotion_loss']),\n",
    "                  'test_emotion_acc: {0:.3f}'.format(test_acc['emotion_acc']),\n",
    "                  'test_confound_loss: {0:.5f}'.format(test_loss['confound_loss']),\n",
    "                  'test_confound_acc: {0:.3f}'.format(test_acc['confound_acc']),\n",
    "                  'test_emotion_uar: {0:.3f}'.format(test_uar['emotion_uar']),\n",
    "                  'test_confound_uar: {0:.3f}'.format(test_uar['confound_uar']))\n",
    "\n",
    "        lr_schedule.step(test_loss['loss'])\n",
    "\n",
    "#         os.makedirs(os.path.join(opt.logger_path, opt.source_domain), exist_ok=True)\n",
    "\n",
    "#         model_file_name = os.path.join(opt.logger_path, opt.source_domain, 'checkpoint.pth.tar')\n",
    "#         state = {'epoch': epoch+1, 'emotion_recognizer': emotion_recognizer.state_dict(), 'opt': opt}\n",
    "#         torch.save(state, model_file_name)\n",
    "\n",
    "        if test_acc['emotion_acc'] > best_acc:\n",
    "#             model_file_name = os.path.join(opt.logger_path, opt.source_domain, 'model.pth.tar')\n",
    "#             torch.save(state, model_file_name)\n",
    "\n",
    "            best_acc = test_acc['emotion_acc']\n",
    "\n",
    "        if test_uar['emotion_uar'] > best_uar:\n",
    "            best_uar = test_uar['emotion_uar']\n",
    "\n",
    "        if es.step(test_loss['emotion_loss']):\n",
    "            break\n",
    "\n",
    "    return best_acc, best_uar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "established-wellington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(train_loader, model, optimizer, criterion, device, verbose = False):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    groundtruth = []\n",
    "    prediction = []\n",
    "\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        visual_features, _, acoustic_features, _, lexical_features, _, _, a_labels, _, _ = train_data # UPDATE\n",
    "\n",
    "        visual_features = visual_features.to(device)\n",
    "        acoustic_features = acoustic_features.to(device)\n",
    "        lexical_features = lexical_features.to(device)\n",
    "\n",
    "        labels = a_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emotion_output, stress_output = model(visual_features, acoustic_features, lexical_features)\n",
    "\n",
    "        emotion_loss = criterion(emotion_output, labels)\n",
    "#         stress_loss = criterion(stress_output, stress_labels)\n",
    "\n",
    "        emotion_loss.backward()\n",
    "#         stress_loss.backward()\n",
    "        \n",
    "        optimizer.step() # do we need two optimizers?\n",
    "        \n",
    "        running_loss += emotion_loss.item()\n",
    "\n",
    "        groundtruth.append(labels.tolist())\n",
    "        predictions = emotion_output.argmax(dim=1, keepdim=True)\n",
    "        prediction.append(predictions.view_as(labels).tolist())\n",
    "\n",
    "        if verbose and i > 0 and int(len(train_loader) / 10) > 0 and i % (int(len(train_loader) / 10)) == 0:\n",
    "            print('.', flush=True, end='')\n",
    "            \n",
    "    train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    groundtruth = list(itertools.chain.from_iterable(groundtruth))\n",
    "    prediction = list(itertools.chain.from_iterable(prediction))\n",
    "\n",
    "    train_acc = accuracy_score(prediction, groundtruth)\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "labeled-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, criterion, device, verbose = False, emotion_dimension = 'arousal'):\n",
    "    model.train()\n",
    "\n",
    "    running_loss = 0.\n",
    "    emotion_running_loss = 0.\n",
    "    confound_running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    emotion_groundtruth = []\n",
    "    emotion_prediction = []\n",
    "    \n",
    "    confound_groundtruth = []\n",
    "    confound_prediction = []\n",
    "\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        visual_features, _, acoustic_features, _, lexical_features, _, v_labels, a_labels, d_labels, s_labels, _ = train_data # UPDATE\n",
    "\n",
    "        visual_features = visual_features.to(device)\n",
    "        acoustic_features = acoustic_features.to(device)\n",
    "        lexical_features = lexical_features.to(device)\n",
    "\n",
    "        if emotion_dimension == 'arousal':\n",
    "            emotion_labels = a_labels.to(device)\n",
    "        elif emotion_dimension == 'valence':\n",
    "            emotion_labels = v_labels.to(device)\n",
    "        else:\n",
    "            print(\"Invalid emotion dimension\")\n",
    "            return\n",
    "        confound_labels = s_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        emotion_predictions, confound_predictions = model(visual_features, acoustic_features, lexical_features)\n",
    "\n",
    "        emotion_loss = criterion(emotion_predictions, emotion_labels)\n",
    "        confound_loss = criterion(confound_predictions, confound_labels)\n",
    "        loss = emotion_loss + confound_loss\n",
    "        \n",
    "        loss.backward()\n",
    "#         emotion_loss.backward()\n",
    "#         confound_loss.backward()\n",
    "        \n",
    "        optimizer.step() # do we need two optimizers?\n",
    "        \n",
    "        emotion_running_loss += emotion_loss.item()\n",
    "        confound_running_loss += confound_loss.item()\n",
    "        running_loss += emotion_running_loss + confound_running_loss\n",
    "\n",
    "        emotion_groundtruth.append(emotion_labels.tolist())\n",
    "        emotion_predictions = emotion_predictions.argmax(dim=1, keepdim=True)\n",
    "        emotion_prediction.append(emotion_predictions.view_as(emotion_labels).tolist())\n",
    "        \n",
    "        confound_groundtruth.append(confound_labels.tolist())\n",
    "        confound_predictions = confound_predictions.argmax(dim=1, keepdim=True)\n",
    "        confound_prediction.append(confound_predictions.view_as(confound_labels).tolist())\n",
    "\n",
    "        if verbose and i > 0 and int(len(train_loader) / 10) > 0 and i % (int(len(train_loader) / 10)) == 0:\n",
    "            print('.', flush=True, end='')\n",
    "        \n",
    "    emotion_loss = emotion_running_loss / len(train_loader)\n",
    "    confound_loss = confound_running_loss / len(train_loader)\n",
    "    loss = running_loss / len(train_loader)\n",
    "    train_loss = {'emotion_loss': emotion_loss,\n",
    "                  'confound_loss': confound_loss,\n",
    "                  'loss': loss\n",
    "                 }\n",
    "\n",
    "    emotion_groundtruth = list(itertools.chain.from_iterable(emotion_groundtruth))\n",
    "    emotion_prediction = list(itertools.chain.from_iterable(emotion_prediction))\n",
    "    \n",
    "    confound_groundtruth = list(itertools.chain.from_iterable(confound_groundtruth))\n",
    "    confound_prediction = list(itertools.chain.from_iterable(confound_prediction))\n",
    "\n",
    "    emotion_acc = accuracy_score(emotion_prediction, emotion_groundtruth)\n",
    "    confound_acc = accuracy_score(confound_prediction, confound_groundtruth)\n",
    "    avg_acc = (emotion_acc + confound_acc) / 2\n",
    "    \n",
    "    train_acc = {'emotion_acc': emotion_acc,\n",
    "                  'confound_acc': confound_acc\n",
    "                }\n",
    "\n",
    "    return train_loss, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "supreme-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_baseline(test_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        groundtruth = []\n",
    "        prediction = []\n",
    "\n",
    "        for i, test_data in enumerate(test_loader):\n",
    "            visual_features, _, acoustic_features, _, lexical_features, _, v_labels, a_labels, d_labels, _ = test_data # UPDATE\n",
    "\n",
    "            visual_features = visual_features.to(device)\n",
    "            acoustic_features = acoustic_features.to(device)\n",
    "            lexical_features = lexical_features.to(device)\n",
    "\n",
    "            labels = a_labels.to(device)\n",
    "\n",
    "            emotion_predictions, confound_predictions = model(visual_features, acoustic_features, lexical_features)\n",
    "            loss = criterion(emotion_predictions, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            groundtruth.append(labels.tolist())\n",
    "            emotion_predictions = emotion_predictions.argmax(dim=1, keepdim=True)\n",
    "            prediction.append(emotion_predictions.view_as(labels).tolist())\n",
    "\n",
    "        test_loss = running_loss / len(test_loader)\n",
    "\n",
    "        groundtruth = list(itertools.chain.from_iterable(groundtruth))\n",
    "        prediction = list(itertools.chain.from_iterable(prediction))\n",
    "\n",
    "        test_acc = accuracy_score(prediction, groundtruth)\n",
    "        test_uar = recall_score(prediction, groundtruth, average='macro')\n",
    "\n",
    "        return test_loss, test_acc, test_uar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "laden-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, criterion, device, emotion_dimension = 'arousal'):\n",
    "    model.eval()\n",
    "\n",
    "    running_loss = 0.\n",
    "    emotion_running_loss = 0.\n",
    "    confound_running_loss = 0.\n",
    "    running_acc = 0.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emotion_groundtruth = []\n",
    "        emotion_prediction = []\n",
    "\n",
    "        confound_groundtruth = []\n",
    "        confound_prediction = []\n",
    "\n",
    "        for i, test_data in enumerate(test_loader):\n",
    "            visual_features, _, acoustic_features, _, lexical_features, _, v_labels, a_labels, d_labels, s_labels, _ = test_data # UPDATE\n",
    "\n",
    "            visual_features = visual_features.to(device)\n",
    "            acoustic_features = acoustic_features.to(device)\n",
    "            lexical_features = lexical_features.to(device)\n",
    "            \n",
    "            if emotion_dimension == 'arousal':\n",
    "                emotion_labels = a_labels.to(device)\n",
    "            elif emotion_dimension == 'valence':\n",
    "                emotion_labels = v_labels.to(device)\n",
    "            else:\n",
    "                print(\"Invalid emotion dimension\")\n",
    "                return\n",
    "            confound_labels = s_labels.to(device)\n",
    "\n",
    "            emotion_predictions, confound_predictions = model(visual_features, acoustic_features, lexical_features)\n",
    "            \n",
    "            emotion_loss = criterion(emotion_predictions, emotion_labels)\n",
    "            confound_loss = criterion(confound_predictions, confound_labels)\n",
    "            loss = emotion_loss + confound_loss\n",
    "\n",
    "            emotion_running_loss += emotion_loss.item()\n",
    "            confound_running_loss += confound_loss.item()\n",
    "            running_loss += emotion_running_loss + confound_running_loss\n",
    "\n",
    "            emotion_groundtruth.append(emotion_labels.tolist())\n",
    "            emotion_predictions = emotion_predictions.argmax(dim=1, keepdim=True)\n",
    "            emotion_prediction.append(emotion_predictions.view_as(emotion_labels).tolist())\n",
    "\n",
    "            confound_groundtruth.append(confound_labels.tolist())\n",
    "            confound_predictions = confound_predictions.argmax(dim=1, keepdim=True)\n",
    "            confound_prediction.append(confound_predictions.view_as(confound_labels).tolist())\n",
    "\n",
    "        emotion_loss = emotion_running_loss / len(train_loader)\n",
    "        confound_loss = confound_running_loss / len(train_loader)\n",
    "        loss = running_loss / len(train_loader)\n",
    "        test_loss = {'emotion_loss': emotion_loss,\n",
    "                     'confound_loss': confound_loss,\n",
    "                     'loss': loss\n",
    "                    }\n",
    "\n",
    "        emotion_groundtruth = list(itertools.chain.from_iterable(emotion_groundtruth))\n",
    "        emotion_prediction = list(itertools.chain.from_iterable(emotion_prediction))\n",
    "\n",
    "        confound_groundtruth = list(itertools.chain.from_iterable(confound_groundtruth))\n",
    "        confound_prediction = list(itertools.chain.from_iterable(confound_prediction))\n",
    "\n",
    "        emotion_acc = accuracy_score(emotion_prediction, emotion_groundtruth)\n",
    "        confound_acc = accuracy_score(confound_prediction, confound_groundtruth)\n",
    "        avg_acc = (emotion_acc + confound_acc) / 2\n",
    "        test_acc = {'emotion_acc': emotion_acc,\n",
    "                    'confound_acc': confound_acc\n",
    "                   }\n",
    "        \n",
    "        emotion_uar = recall_score(emotion_prediction, emotion_groundtruth, average='macro')\n",
    "        confound_uar = recall_score(confound_prediction, confound_groundtruth, average='macro')\n",
    "\n",
    "        test_uar = {'emotion_uar': emotion_uar,\n",
    "                    'confound_uar': confound_uar\n",
    "                   }\n",
    "\n",
    "        return test_loss, test_acc, test_uar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aggregate-might",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-morning",
   "metadata": {},
   "source": [
    "## Train + Test for Valence and Arousal with adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "regulation-february",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Train loss: {'emotion_loss': 1.0375580579506285, 'confound_loss': 0.7042247983500187, 'loss': 907.3973454224229}\n",
      "Train acc: {'emotion_acc': 0.5260340632603406, 'confound_acc': 0.45985401459854014}\n",
      "Train loss: {'emotion_loss': 1.0015043317691825, 'confound_loss': 0.7102102986917421, 'loss': 883.0994067238463}\n",
      "Train acc: {'emotion_acc': 0.5447688564476886, 'confound_acc': 0.49635036496350365}\n",
      "Train loss: {'emotion_loss': 0.9888509675454537, 'confound_loss': 0.689915830986973, 'loss': 863.3553421946119}\n",
      "Train acc: {'emotion_acc': 0.5520681265206813, 'confound_acc': 0.5181265206812652}\n",
      "Train loss: {'emotion_loss': 0.9808055925462033, 'confound_loss': 0.696835444479137, 'loss': 866.1516288383809}\n",
      "Train acc: {'emotion_acc': 0.5615571776155718, 'confound_acc': 0.4701946472019465}\n",
      "Train loss: {'emotion_loss': 0.9833080192832168, 'confound_loss': 0.6920242874306928, 'loss': 862.7224710272908}\n",
      "Train acc: {'emotion_acc': 0.5436739659367397, 'confound_acc': 0.5274939172749392}\n",
      "Train loss: {'emotion_loss': 0.9638202780067688, 'confound_loss': 0.6935965352717077, 'loss': 853.9164763729628}\n",
      "Train acc: {'emotion_acc': 0.5665450121654502, 'confound_acc': 0.5007299270072992}\n",
      "Train loss: {'emotion_loss': 0.9412118702083246, 'confound_loss': 0.6942478034514862, 'loss': 844.2932217881837}\n",
      "Train acc: {'emotion_acc': 0.6003649635036497, 'confound_acc': 0.47664233576642334}\n",
      "Train loss: {'emotion_loss': 0.9280061158224766, 'confound_loss': 0.6922764928888254, 'loss': 838.2610376408244}\n",
      "Train acc: {'emotion_acc': 0.6158150851581509, 'confound_acc': 0.522992700729927}\n",
      "Train loss: {'emotion_loss': 0.8951059677837424, 'confound_loss': 0.6947644876482886, 'loss': 818.663626900037}\n",
      "Train acc: {'emotion_acc': 0.6519464720194648, 'confound_acc': 0.48929440389294404}\n",
      "Train loss: {'emotion_loss': 0.8767445310660373, 'confound_loss': 0.6922456962473198, 'loss': 810.2324004524065}\n",
      "Train acc: {'emotion_acc': 0.6717761557177615, 'confound_acc': 0.5301703163017032}\n",
      "Train loss: {'emotion_loss': 0.8623518774481599, 'confound_loss': 0.6935401720643507, 'loss': 799.9013769878835}\n",
      "Train acc: {'emotion_acc': 0.6874695863746959, 'confound_acc': 0.4968369829683698}\n",
      "Train loss: {'emotion_loss': 0.8473604272195802, 'confound_loss': 0.6946565041514222, 'loss': 794.574257370215}\n",
      "Train acc: {'emotion_acc': 0.7004866180048662, 'confound_acc': 0.4867396593673966}\n",
      "Train loss: {'emotion_loss': 0.8440477080962073, 'confound_loss': 0.6926400513036706, 'loss': 795.3336827961967}\n",
      "Train acc: {'emotion_acc': 0.7074209245742092, 'confound_acc': 0.5159367396593674}\n",
      "Train loss: {'emotion_loss': 0.8410594361881337, 'confound_loss': 0.6936105935606047, 'loss': 792.2789688474473}\n",
      "Train acc: {'emotion_acc': 0.7086374695863747, 'confound_acc': 0.4992700729927007}\n",
      "Train loss: {'emotion_loss': 0.8225741671680941, 'confound_loss': 0.6961128037959221, 'loss': 780.4708250137735}\n",
      "Train acc: {'emotion_acc': 0.7290754257907542, 'confound_acc': 0.43442822384428226}\n",
      "Train loss: {'emotion_loss': 0.8161572284619631, 'confound_loss': 0.6936078805056064, 'loss': 776.271050237786}\n",
      "Train acc: {'emotion_acc': 0.7341849148418491, 'confound_acc': 0.4913625304136253}\n",
      "Train loss: {'emotion_loss': 0.8233948167891818, 'confound_loss': 0.6942604292575487, 'loss': 780.257511173009}\n",
      "Train acc: {'emotion_acc': 0.7266423357664233, 'confound_acc': 0.47287104622871046}\n",
      "Train loss: {'emotion_loss': 0.8171027465669097, 'confound_loss': 0.6946099524600032, 'loss': 778.3390976980271}\n",
      "Train acc: {'emotion_acc': 0.733941605839416, 'confound_acc': 0.4705596107055961}\n",
      "Train loss: {'emotion_loss': 0.8064040739944472, 'confound_loss': 0.6928786613945831, 'loss': 771.527434669638}\n",
      "Train acc: {'emotion_acc': 0.7436739659367396, 'confound_acc': 0.5139902676399026}\n",
      "Train loss: {'emotion_loss': 0.8057253785750281, 'confound_loss': 0.6944052608908382, 'loss': 772.8099720376011}\n",
      "Train acc: {'emotion_acc': 0.7448905109489051, 'confound_acc': 0.48686131386861314}\n",
      "Train loss: {'emotion_loss': 0.8070413177463331, 'confound_loss': 0.6926765168803212, 'loss': 771.8499259917421}\n",
      "Train acc: {'emotion_acc': 0.7431873479318735, 'confound_acc': 0.5064476885644769}\n",
      "Train loss: {'emotion_loss': 0.8086424490821037, 'confound_loss': 0.6938743362862776, 'loss': 772.9118188003274}\n",
      "Train acc: {'emotion_acc': 0.7413625304136253, 'confound_acc': 0.48309002433090026}\n",
      "Train loss: {'emotion_loss': 0.8025271379414236, 'confound_loss': 0.6933353483560948, 'loss': 771.3450702188776}\n",
      "Train acc: {'emotion_acc': 0.7463503649635036, 'confound_acc': 0.5006082725060828}\n",
      "Train loss: {'emotion_loss': 0.7911428269941055, 'confound_loss': 0.6934412609974234, 'loss': 765.8682919553977}\n",
      "Train acc: {'emotion_acc': 0.7591240875912408, 'confound_acc': 0.49002433090024333}\n",
      "Train loss: {'emotion_loss': 0.7994282824867894, 'confound_loss': 0.6934436545181831, 'loss': 769.7881771050654}\n",
      "Train acc: {'emotion_acc': 0.7495133819951338, 'confound_acc': 0.5025547445255475}\n",
      "Train loss: {'emotion_loss': 0.7880138497988074, 'confound_loss': 0.6933000922087101, 'loss': 763.3685756889299}\n",
      "Train acc: {'emotion_acc': 0.7618004866180048, 'confound_acc': 0.5051094890510949}\n",
      "Train loss: {'emotion_loss': 0.791207299158267, 'confound_loss': 0.6933257038259321, 'loss': 761.3276528145552}\n",
      "Train acc: {'emotion_acc': 0.7591240875912408, 'confound_acc': 0.5127737226277372}\n",
      "Train loss: {'emotion_loss': 0.7889061981254051, 'confound_loss': 0.693442244416081, 'loss': 763.0609035831134}\n",
      "Train acc: {'emotion_acc': 0.7609489051094891, 'confound_acc': 0.4944038929440389}\n",
      "Train loss: {'emotion_loss': 0.7835074710706792, 'confound_loss': 0.6933746644611025, 'loss': 761.0948644087356}\n",
      "Train acc: {'emotion_acc': 0.7656934306569343, 'confound_acc': 0.4975669099756691}\n",
      "Train loss: {'emotion_loss': 0.7873772408247922, 'confound_loss': 0.6929030999947151, 'loss': 759.9289897061624}\n",
      "Train acc: {'emotion_acc': 0.7616788321167883, 'confound_acc': 0.5141119221411192}\n",
      "Train loss: {'emotion_loss': 0.772962022732204, 'confound_loss': 0.6937805607277132, 'loss': 754.0006598591921}\n",
      "Train acc: {'emotion_acc': 0.7762773722627737, 'confound_acc': 0.4905109489051095}\n",
      "Train loss: {'emotion_loss': 0.7849181307197081, 'confound_loss': 0.6929499018169099, 'loss': 761.4233225574174}\n",
      "Train acc: {'emotion_acc': 0.7648418491484185, 'confound_acc': 0.5144768856447689}\n",
      "Train loss: {'emotion_loss': 0.7867028705688766, 'confound_loss': 0.6935866530187399, 'loss': 763.5965798796383}\n",
      "Train acc: {'emotion_acc': 0.7632603406326034, 'confound_acc': 0.49063260340632603}\n",
      "Train loss: {'emotion_loss': 0.7864468410205284, 'confound_loss': 0.693328340867614, 'loss': 760.9971614381451}\n",
      "Train acc: {'emotion_acc': 0.7631386861313869, 'confound_acc': 0.501338199513382}\n",
      "Train loss: {'emotion_loss': 0.780319840875581, 'confound_loss': 0.6932964790539983, 'loss': 760.2397283532508}\n",
      "Train acc: {'emotion_acc': 0.7690997566909976, 'confound_acc': 0.5038929440389295}\n",
      "Train loss: {'emotion_loss': 0.7857190357224023, 'confound_loss': 0.693456165463544, 'loss': 759.6055112864952}\n",
      "Train acc: {'emotion_acc': 0.764720194647202, 'confound_acc': 0.5087591240875913}\n",
      "Train loss: {'emotion_loss': 0.7681906923129864, 'confound_loss': 0.6932139692371457, 'loss': 752.0259300837373}\n",
      "Train acc: {'emotion_acc': 0.7816301703163017, 'confound_acc': 0.5010948905109489}\n",
      "Train loss: {'emotion_loss': 0.7801380344749889, 'confound_loss': 0.6933660520537818, 'loss': 760.3610885498705}\n",
      "Train acc: {'emotion_acc': 0.7697080291970803, 'confound_acc': 0.4979318734793187}\n",
      "Train loss: {'emotion_loss': 0.7716578460852923, 'confound_loss': 0.6936232877264691, 'loss': 755.5083878016542}\n",
      "Train acc: {'emotion_acc': 0.7789537712895377, 'confound_acc': 0.4929440389294404}\n",
      "Train loss: {'emotion_loss': 0.7725640829319156, 'confound_loss': 0.6933111011518115, 'loss': 752.8428224107171}\n",
      "Train acc: {'emotion_acc': 0.7778588807785888, 'confound_acc': 0.5015815085158151}\n",
      "Train loss: {'emotion_loss': 0.7661354901261831, 'confound_loss': 0.6934424283323585, 'loss': 750.0064624699869}\n",
      "Train acc: {'emotion_acc': 0.7849148418491484, 'confound_acc': 0.5047445255474453}\n",
      "Train loss: {'emotion_loss': 0.7756380997743124, 'confound_loss': 0.6931951110349092, 'loss': 754.897769418614}\n",
      "Train acc: {'emotion_acc': 0.7736009732360097, 'confound_acc': 0.49562043795620436}\n",
      "Train loss: {'emotion_loss': 0.7761555835894574, 'confound_loss': 0.6935912358505717, 'loss': 756.0822393933043}\n",
      "Train acc: {'emotion_acc': 0.7734793187347931, 'confound_acc': 0.49878345498783455}\n",
      "Train loss: {'emotion_loss': 0.7720975700171541, 'confound_loss': 0.6932434897710377, 'loss': 753.5653991644716}\n",
      "Train acc: {'emotion_acc': 0.7755474452554745, 'confound_acc': 0.5036496350364964}\n",
      "Train loss: {'emotion_loss': 0.7624610402124865, 'confound_loss': 0.69379326886704, 'loss': 749.0279838998262}\n",
      "Train acc: {'emotion_acc': 0.7843065693430656, 'confound_acc': 0.48418491484184917}\n",
      "Train loss: {'emotion_loss': 0.7659475681034972, 'confound_loss': 0.6932567937248876, 'loss': 750.16505688023}\n",
      "Train acc: {'emotion_acc': 0.7839416058394161, 'confound_acc': 0.5075425790754258}\n",
      "Train loss: {'emotion_loss': 0.7621721166696994, 'confound_loss': 0.6934012103289482, 'loss': 749.0561535370605}\n",
      "Train acc: {'emotion_acc': 0.787712895377129, 'confound_acc': 0.5063260340632604}\n",
      "Train loss: {'emotion_loss': 0.7637984787443732, 'confound_loss': 0.6932812486757101, 'loss': 749.4371670450334}\n",
      "Train acc: {'emotion_acc': 0.7841849148418492, 'confound_acc': 0.4912408759124088}\n",
      "Train loss: {'emotion_loss': 0.7620659799891223, 'confound_loss': 0.6934567971104314, 'loss': 746.7809344341086}\n",
      "Train acc: {'emotion_acc': 0.787956204379562, 'confound_acc': 0.5097323600973236}\n",
      "Train loss: {'emotion_loss': 0.7567709973118184, 'confound_loss': 0.6932437825759561, 'loss': 743.0867550785904}\n",
      "Train acc: {'emotion_acc': 0.7935523114355231, 'confound_acc': 0.5052311435523115}\n"
     ]
    }
   ],
   "source": [
    "emotion_recognizer = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False, grl_lambda = 10)\n",
    "init_weights(emotion_recognizer)\n",
    "for param in emotion_recognizer.parameters():\n",
    "    param.requires_grad = True\n",
    "emotion_recognizer.to(device)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(emotion_recognizer.parameters(), lr=learning_rate)\n",
    "lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset_file_path = '../dataset/IEMOCAP/0/train.csv'\n",
    "train_loader = datasets.get_dataloader(train_dataset_file_path, 'train')\n",
    "test_dataset_file_path = '../dataset/IEMOCAP/0/test.csv'\n",
    "test_loader = datasets.get_dataloader(test_dataset_file_path, 'test')\n",
    "\n",
    "emotion_loss = []\n",
    "confound_loss = []\n",
    "loss = []\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(train_loader, emotion_recognizer, optimizer, criterion, device, emotion_dimension = 'valence')\n",
    "    emotion_loss.append(train_loss['emotion_loss'])\n",
    "    confound_loss.append(train_loss['confound_loss'])\n",
    "    loss.append(train_loss['loss'])\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Train acc: {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "opposed-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: {'emotion_loss': 0.19880297084262863, 'confound_loss': 0.15487182691171475, 'loss': 40.63831671191097}\n",
      "Test acc: {'emotion_acc': 0.6382627817482133, 'confound_acc': 0.4161627267729522}\n",
      "Test uar: {'emotion_uar': 0.5135301964271702, 'confound_uar': 0.20831040176114474}\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_uar = test(test_loader, emotion_recognizer, criterion, device, emotion_dimension = 'valence')\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test acc: {test_acc}')\n",
    "print(f'Test uar: {test_uar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "future-traveler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd05c0e6d90>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(range(epochs), loss, label = 'train loss')\n",
    "plt.plot(range(epochs), emotion_loss, label = 'Valence loss')\n",
    "plt.plot(range(epochs), confound_loss, label = 'Confound loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "minute-milwaukee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Train loss: {'emotion_loss': 1.0985497480932376, 'confound_loss': 0.7106467704016874, 'loss': 928.1546192409231}\n",
      "Train acc: {'emotion_acc': 0.3381995133819951, 'confound_acc': 0.41654501216545015}\n",
      "Train loss: {'emotion_loss': 1.0980465866712281, 'confound_loss': 0.695121268527981, 'loss': 924.8123345960091}\n",
      "Train acc: {'emotion_acc': 0.34051094890510947, 'confound_acc': 0.49695863746958635}\n",
      "Train loss: {'emotion_loss': 1.0969520301670417, 'confound_loss': 0.697640994353517, 'loss': 922.9997329174429}\n",
      "Train acc: {'emotion_acc': 0.3518248175182482, 'confound_acc': 0.506934306569343}\n",
      "Train loss: {'emotion_loss': 1.0961679816246033, 'confound_loss': 0.693727838621993, 'loss': 921.8148984324027}\n",
      "Train acc: {'emotion_acc': 0.36666666666666664, 'confound_acc': 0.51338199513382}\n",
      "Train loss: {'emotion_loss': 1.091367721789542, 'confound_loss': 0.6935881097377042, 'loss': 918.520590931699}\n",
      "Train acc: {'emotion_acc': 0.382360097323601, 'confound_acc': 0.4975669099756691}\n",
      "Train loss: {'emotion_loss': 1.0844953036377867, 'confound_loss': 0.6938886975267982, 'loss': 916.3804633628417}\n",
      "Train acc: {'emotion_acc': 0.4048661800486618, 'confound_acc': 0.49744525547445256}\n",
      "Train loss: {'emotion_loss': 1.0736680912716379, 'confound_loss': 0.6923483795692948, 'loss': 908.7375917815049}\n",
      "Train acc: {'emotion_acc': 0.4212895377128954, 'confound_acc': 0.5110705596107056}\n",
      "Train loss: {'emotion_loss': 1.0551568019250952, 'confound_loss': 0.6952209075485222, 'loss': 901.4749825433303}\n",
      "Train acc: {'emotion_acc': 0.4492700729927007, 'confound_acc': 0.45255474452554745}\n",
      "Train loss: {'emotion_loss': 1.0314601133305739, 'confound_loss': 0.6921745472613012, 'loss': 888.0116930317554}\n",
      "Train acc: {'emotion_acc': 0.4751824817518248, 'confound_acc': 0.5295620437956204}\n",
      "Train loss: {'emotion_loss': 1.011447669583072, 'confound_loss': 0.6934750223901949, 'loss': 878.7677216706688}\n",
      "Train acc: {'emotion_acc': 0.5085158150851582, 'confound_acc': 0.5047445255474453}\n",
      "Train loss: {'emotion_loss': 0.9999137643130372, 'confound_loss': 0.6926305113135609, 'loss': 871.6312365464663}\n",
      "Train acc: {'emotion_acc': 0.5233576642335767, 'confound_acc': 0.5183698296836983}\n",
      "Train loss: {'emotion_loss': 0.983454745741206, 'confound_loss': 0.6928925434786986, 'loss': 863.3865871548305}\n",
      "Train acc: {'emotion_acc': 0.5441605839416058, 'confound_acc': 0.5190997566909976}\n",
      "Train loss: {'emotion_loss': 0.9678964075643265, 'confound_loss': 0.6926601521004034, 'loss': 855.1232790062168}\n",
      "Train acc: {'emotion_acc': 0.5638686131386861, 'confound_acc': 0.5226277372262774}\n",
      "Train loss: {'emotion_loss': 0.9665920703675497, 'confound_loss': 0.6933909507345133, 'loss': 853.2495554812572}\n",
      "Train acc: {'emotion_acc': 0.5655717761557177, 'confound_acc': 0.5091240875912408}\n",
      "Train loss: {'emotion_loss': 0.9528792689514531, 'confound_loss': 0.6931990747437867, 'loss': 846.4842793553604}\n",
      "Train acc: {'emotion_acc': 0.582360097323601, 'confound_acc': 0.5047445255474453}\n",
      "Train loss: {'emotion_loss': 0.9393500935010873, 'confound_loss': 0.6941741381985668, 'loss': 842.4823005467886}\n",
      "Train acc: {'emotion_acc': 0.6057177615571776, 'confound_acc': 0.48309002433090026}\n",
      "Train loss: {'emotion_loss': 0.9311927393484672, 'confound_loss': 0.69284103404919, 'loss': 835.6988061670547}\n",
      "Train acc: {'emotion_acc': 0.6111922141119221, 'confound_acc': 0.5077858880778588}\n",
      "Train loss: {'emotion_loss': 0.9203473995167921, 'confound_loss': 0.6950277909346592, 'loss': 832.7361038273874}\n",
      "Train acc: {'emotion_acc': 0.627007299270073, 'confound_acc': 0.46581508515815084}\n",
      "Train loss: {'emotion_loss': 0.9184456786524925, 'confound_loss': 0.6930490575064017, 'loss': 829.6615363325243}\n",
      "Train acc: {'emotion_acc': 0.6287104622871046, 'confound_acc': 0.510705596107056}\n",
      "Train loss: {'emotion_loss': 0.9129536485277725, 'confound_loss': 0.6941425393295659, 'loss': 827.280690391124}\n",
      "Train acc: {'emotion_acc': 0.6347931873479319, 'confound_acc': 0.49695863746958635}\n",
      "Train loss: {'emotion_loss': 0.9011809508740206, 'confound_loss': 0.6934679438747785, 'loss': 820.5870676281851}\n",
      "Train acc: {'emotion_acc': 0.6503649635036496, 'confound_acc': 0.5036496350364964}\n",
      "Train loss: {'emotion_loss': 0.8856960776830926, 'confound_loss': 0.6930757858409956, 'loss': 812.261448704489}\n",
      "Train acc: {'emotion_acc': 0.6641119221411192, 'confound_acc': 0.5065693430656935}\n",
      "Train loss: {'emotion_loss': 0.8862898026227023, 'confound_loss': 0.6936696369476355, 'loss': 814.8091491689246}\n",
      "Train acc: {'emotion_acc': 0.6684914841849149, 'confound_acc': 0.49878345498783455}\n",
      "Train loss: {'emotion_loss': 0.8809845322300952, 'confound_loss': 0.6930424221410826, 'loss': 809.7092097285656}\n",
      "Train acc: {'emotion_acc': 0.6725060827250608, 'confound_acc': 0.5066909975669099}\n",
      "Train loss: {'emotion_loss': 0.873124563682404, 'confound_loss': 0.6932004395625935, 'loss': 805.6909505207715}\n",
      "Train acc: {'emotion_acc': 0.6774939172749391, 'confound_acc': 0.504257907542579}\n",
      "Train loss: {'emotion_loss': 0.8654416812880957, 'confound_loss': 0.6932899547806046, 'loss': 801.6095911390819}\n",
      "Train acc: {'emotion_acc': 0.6864963503649635, 'confound_acc': 0.5024330900243309}\n",
      "Train loss: {'emotion_loss': 0.8591916777976292, 'confound_loss': 0.6935544724246407, 'loss': 798.935223286196}\n",
      "Train acc: {'emotion_acc': 0.6952554744525548, 'confound_acc': 0.4948905109489051}\n",
      "Train loss: {'emotion_loss': 0.8602198140282575, 'confound_loss': 0.6934278732027989, 'loss': 799.194018800319}\n",
      "Train acc: {'emotion_acc': 0.6883211678832116, 'confound_acc': 0.5088807785888078}\n",
      "Train loss: {'emotion_loss': 0.8476723322376667, 'confound_loss': 0.693445082768392, 'loss': 792.9046843245568}\n",
      "Train acc: {'emotion_acc': 0.7035279805352798, 'confound_acc': 0.4989051094890511}\n",
      "Train loss: {'emotion_loss': 0.8463665442360051, 'confound_loss': 0.693369115025153, 'loss': 791.9983545745857}\n",
      "Train acc: {'emotion_acc': 0.704014598540146, 'confound_acc': 0.4982968369829684}\n",
      "Train loss: {'emotion_loss': 0.8420210441842617, 'confound_loss': 0.6936437985080689, 'loss': 790.6458192661347}\n",
      "Train acc: {'emotion_acc': 0.7094890510948905, 'confound_acc': 0.4944038929440389}\n",
      "Train loss: {'emotion_loss': 0.8392992302021628, 'confound_loss': 0.6933773929390926, 'loss': 788.7428317207423}\n",
      "Train acc: {'emotion_acc': 0.710948905109489, 'confound_acc': 0.502919708029197}\n",
      "Train loss: {'emotion_loss': 0.8376211277589724, 'confound_loss': 0.6935592983135453, 'loss': 785.64530914732}\n",
      "Train acc: {'emotion_acc': 0.7153284671532847, 'confound_acc': 0.498661800486618}\n",
      "Train loss: {'emotion_loss': 0.8270222501184226, 'confound_loss': 0.6936031573593384, 'loss': 781.9229662461272}\n",
      "Train acc: {'emotion_acc': 0.7216545012165451, 'confound_acc': 0.49111922141119224}\n",
      "Train loss: {'emotion_loss': 0.8218941556340525, 'confound_loss': 0.6933888686886094, 'loss': 778.178221630505}\n",
      "Train acc: {'emotion_acc': 0.7321167883211679, 'confound_acc': 0.49805352798053526}\n",
      "Train loss: {'emotion_loss': 0.8203432446323944, 'confound_loss': 0.6935590118285747, 'loss': 781.5167205413144}\n",
      "Train acc: {'emotion_acc': 0.7338199513381995, 'confound_acc': 0.4918491484184915}\n",
      "Train loss: {'emotion_loss': 0.8136925092003224, 'confound_loss': 0.6933633211985636, 'loss': 777.6779194921255}\n",
      "Train acc: {'emotion_acc': 0.7391727493917275, 'confound_acc': 0.49695863746958635}\n",
      "Train loss: {'emotion_loss': 0.8090677087988835, 'confound_loss': 0.69353513065943, 'loss': 773.4444541744452}\n",
      "Train acc: {'emotion_acc': 0.7425790754257907, 'confound_acc': 0.4922141119221411}\n",
      "Train loss: {'emotion_loss': 0.8153305645698703, 'confound_loss': 0.693074826368562, 'loss': 774.3978080779082}\n",
      "Train acc: {'emotion_acc': 0.7330900243309002, 'confound_acc': 0.5104622871046228}\n",
      "Train loss: {'emotion_loss': 0.8127408048522148, 'confound_loss': 0.692837248226548, 'loss': 772.9010335419777}\n",
      "Train acc: {'emotion_acc': 0.7386861313868613, 'confound_acc': 0.5201946472019465}\n",
      "Train loss: {'emotion_loss': 0.8129233849535656, 'confound_loss': 0.6934062425148626, 'loss': 775.8118328959446}\n",
      "Train acc: {'emotion_acc': 0.7361313868613139, 'confound_acc': 0.4964720194647202}\n",
      "Train loss: {'emotion_loss': 0.7999252534909935, 'confound_loss': 0.6929289993145122, 'loss': 768.5502080344504}\n",
      "Train acc: {'emotion_acc': 0.7537712895377129, 'confound_acc': 0.5097323600973236}\n",
      "Train loss: {'emotion_loss': 0.7954530099022713, 'confound_loss': 0.6939250863943582, 'loss': 764.9782956470427}\n",
      "Train acc: {'emotion_acc': 0.7557177615571776, 'confound_acc': 0.4852798053527981}\n",
      "Train loss: {'emotion_loss': 0.7935842302870658, 'confound_loss': 0.6931942035136056, 'loss': 764.3937819222648}\n",
      "Train acc: {'emotion_acc': 0.7579075425790754, 'confound_acc': 0.49987834549878346}\n",
      "Train loss: {'emotion_loss': 0.7932844769629986, 'confound_loss': 0.6937494742383289, 'loss': 765.8132400072618}\n",
      "Train acc: {'emotion_acc': 0.7585158150851582, 'confound_acc': 0.48722627737226276}\n",
      "Train loss: {'emotion_loss': 0.794711689830754, 'confound_loss': 0.6930848240040619, 'loss': 765.1915313098217}\n",
      "Train acc: {'emotion_acc': 0.7543795620437956, 'confound_acc': 0.502919708029197}\n",
      "Train loss: {'emotion_loss': 0.7871425851657696, 'confound_loss': 0.6931742189691225, 'loss': 761.5928950915657}\n",
      "Train acc: {'emotion_acc': 0.7653284671532846, 'confound_acc': 0.4972019464720195}\n",
      "Train loss: {'emotion_loss': 0.7892121667412004, 'confound_loss': 0.6931703237939901, 'loss': 761.9832082945665}\n",
      "Train acc: {'emotion_acc': 0.76338199513382, 'confound_acc': 0.5102189781021897}\n",
      "Train loss: {'emotion_loss': 0.7934051209966496, 'confound_loss': 0.6933836309014592, 'loss': 764.082160001541}\n",
      "Train acc: {'emotion_acc': 0.7565693430656935, 'confound_acc': 0.5088807785888078}\n",
      "Train loss: {'emotion_loss': 0.7800519127790102, 'confound_loss': 0.6932661804707597, 'loss': 757.1938635746329}\n",
      "Train acc: {'emotion_acc': 0.7718978102189781, 'confound_acc': 0.49659367396593673}\n"
     ]
    }
   ],
   "source": [
    "emotion_recognizer = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False, grl_lambda = 10)\n",
    "init_weights(emotion_recognizer)\n",
    "for param in emotion_recognizer.parameters():\n",
    "    param.requires_grad = True\n",
    "emotion_recognizer.to(device)\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(emotion_recognizer.parameters(), lr=learning_rate)\n",
    "lr_schedule = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=1)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "train_dataset_file_path = '../dataset/IEMOCAP/0/train.csv'\n",
    "train_loader = datasets.get_dataloader(train_dataset_file_path, 'train')\n",
    "test_dataset_file_path = '../dataset/IEMOCAP/0/test.csv'\n",
    "test_loader = datasets.get_dataloader(test_dataset_file_path, 'test')\n",
    "\n",
    "emotion_loss = []\n",
    "confound_loss = []\n",
    "loss = []\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss, train_acc = train(train_loader, emotion_recognizer, optimizer, criterion, device, emotion_dimension = 'arousal')\n",
    "    emotion_loss.append(train_loss['emotion_loss'])\n",
    "    confound_loss.append(train_loss['confound_loss'])\n",
    "    loss.append(train_loss['loss'])\n",
    "    print(f'Train loss: {train_loss}')\n",
    "    print(f'Train acc: {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "inside-lodging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: {'emotion_loss': 0.22401398930568175, 'confound_loss': 0.1532518744816576, 'loss': 43.474208978943324}\n",
      "Test acc: {'emotion_acc': 0.520065970313359, 'confound_acc': 0.576690489279824}\n",
      "Test uar: {'emotion_uar': 0.5428415150202098, 'confound_uar': 0.4891664351802389}\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_uar = test(test_loader, emotion_recognizer, criterion, device, emotion_dimension = 'arousal')\n",
    "print(f'Test loss: {test_loss}')\n",
    "print(f'Test acc: {test_acc}')\n",
    "print(f'Test uar: {test_uar}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mental-pharmacy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd036581d60>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8+yak3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzj0lEQVR4nO3deXwU9f348dd7j9wHgYQzQCKXhBsiqICAWgSlImotKCoq9YuKbW212lal0vpT641aLUVErQUVq0VFUTkEFIWA3GcEIQlHQiAhB7k2n98fMwlrhGSBJJts3s/HYx6zc+57dmff89mZz3xGjDEopZQKXA5/B6CUUqpuaaJXSqkAp4leKaUCnCZ6pZQKcJrolVIqwLn8HUBVsbGxJiEhwd9hKKVUo7J27drDxpi4k01rcIk+ISGBlJQUf4ehlFKNiojsPdU0PXWjlFIBThO9UkoFOE30SikV4BrcOXqllP+UlpaSnp5OUVGRv0NRpxASEkJ8fDxut9vnZWpM9CIyGxgDZBpjep5k+rnAa0B/4M/GmKe8po0CngecwCxjzOM+R6aUqnfp6elERkaSkJCAiPg7HFWFMYbs7GzS09NJTEz0eTlfTt3MAUZVM/0I8GvgKe+RIuIEXgJGA0nABBFJ8jkypVS9KyoqokWLFprkGygRoUWLFqf9j6vGRG+MWY6VzE81PdMYswYorTJpIJBqjNltjCkB5gFjTys6pVS90yTfsJ3J91OX5+jbAWlew+nAoLp6s6JSDy8uSSU0yEmI20mo20lokINQtzUcHeomNiKYFhFBhAXppQmlVNPRIDKeiNwO3A7QoUOHM1pHXlEZ/1iWSrkPzeuHup20iAiiRUQwzcPcRIW6iQxxERXiJjLETVSoizbRIQzuHEuwy3lG8SilztwHH3zAuHHj2LZtG+eee65fYvjLX/5CREQE9957r0/jG7K6TPQZQHuv4Xh73E8YY2YCMwGSk5PP6EkocZHBfP//LqfEU05RSTnHSz1WV+LheGkZucdLOZxfQnZ+Cdn5xWQXlHA4v5is/GJ2Hy4gr6iMY8dLKfM6UjQLczO2T1uuHdCenu2i9C+tUvVk7ty5DBkyhLlz5/LII4/8ZHpZWRkuV4MopzYKdflJrQG6iEgiVoIfD1xfh++HiBDschLschKN71WPKhhjOF7q4djxMrYfPMZ76zKYuyaN11ftpVurSK4dEM9V/doRFxlcB9ErpQDy8/NZuXIlS5cu5ec//3llol+2bBkPPfQQMTExbN++nY0bN3LHHXeQkpKCy+XimWeeYcSIEcyZM4eUlBRefPFFAMaMGcO9997L0KFDue2220hJSUFEuPXWW7nnnnv417/+xcyZMykpKaFz5868+eabhIWF+RTr+vXrmTJlCoWFhXTq1InZs2cTExPDjBkzeOWVV3C5XCQlJTFv3jy+/PJLfvOb3wBWrlq+fDmRkZF18yFW4Uv1yrnAcCBWRNKBaWBlUWPMKyLSGkgBooByEfktkGSMOSYiU4FFWNUrZxtjttTJVtQSESEsyEVYkIvW0SEM79aS3MJSPty4n/lr03l04Tae+HQ74we259eXdKFlZIi/Q1aqzjzy4Ra27j9Wq+tMahvFtJ/3qHae//3vf4waNYquXbvSokUL1q5dy4ABAwBYt24dmzdvJjExkaeffhoRYdOmTWzfvp2RI0eyc+fOU653/fr1ZGRksHnzZgBycnIAuPrqq/nVr34FwIMPPsirr77K3Xff7dP23HTTTbzwwgsMGzaMhx9+mEceeYTnnnuOxx9/nD179hAcHFz5Pk899RQvvfQSgwcPJj8/n5CQ+ssfvtS6mWCMaWOMcRtj4o0xrxpjXjHGvGJPP2iPjzLGNLNfH7OnLTTGdDXGdDLGPFrXG1MXosPcTDy/Ix/cNZgvfncR4we2Z97qNIb9fRnPfLaDvKKqlY2UUmdj7ty5jB8/HoDx48czd+7cymkDBw6srD++cuVKJk6cCMC5555Lx44dq03055xzDrt37+buu+/m008/JSoqCoDNmzczdOhQevXqxVtvvcWWLb6VR3Nzc8nJyWHYsGEA3HzzzSxfvhyA3r17c8MNN/Dvf/+78hTT4MGD+d3vfseMGTPIycmp11NPepLrNHRuGcnfrurF5CHn8NRnO5ixJJV/f7uPqSM6c8P5HfTCrQooNZW868KRI0dYsmQJmzZtQkTweDyICE8++SQA4eHhNa7D5XJRXl5eOVxR5zwmJoYNGzawaNEiXnnlFd555x1mz57NpEmT+OCDD+jTpw9z5sxh2bJlZ70dH3/8McuXL+fDDz/k0UcfZdOmTTzwwANcccUVLFy4kMGDB7No0aJ6u9Csbd2cgYTYcF68vj8Lpg7m3NaRTP9oK5c8/SVfpR72d2hKNWrz58/nxhtvZO/evfzwww+kpaWRmJjIihUrfjLv0KFDeeuttwDYuXMn+/bto1u3biQkJLB+/XrKy8tJS0tj9erVABw+fJjy8nKuueYa/va3v7Fu3ToA8vLyaNOmDaWlpZXr80V0dDQxMTGVsb355psMGzas8n1HjBjBE088QW5uLvn5+Xz//ff06tWL+++/n/POO4/t27ef7cflMy3Rn4Xe8c14a/IgVuw6zPSPtnLT7NVMH9uDGwZ19HdoSjVKc+fO5f777//RuGuuuYa5c+fyy1/+8kfj77zzTu644w569eqFy+Vizpw5BAcHM3jwYBITE0lKSqJ79+70798fgIyMDG655ZbK0v5jjz0GwF//+lcGDRpEXFwcgwYNIi8vz+d4X3/99cqLseeccw6vvfYaHo+HiRMnkpubizGGX//61zRr1oyHHnqIpUuX4nA46NGjB6NHjz6bj+q0iDFnVJuxziQnJ5vG+OCRvKJS7p77Hct2ZHHbkET+dHl3nA6tjqkal23bttG9e3d/h6FqcLLvSUTWGmOSTza/nrqpJZEhbmbdlMykCxN4deUe/u/NFAqKy/wdllJKaaKvTS6ng79c2YPpY3uwZHsm176yiv05x/0dllKqidNEXwduuiCB2ZPOI+1IIVe99BWbM3L9HZJSqgnTRF9HhndryXt3XIjb6WDy6ynkFmp9e6WUf2iir0PdWkfy8sT+HM4vZtqCzf4ORynVRGmir2O945tx98Vd+GD9fj7eeMDf4SilmiBN9PXgzhGd6BMfzZ8/2ETmMX0Wp1LVOXjwIOPHj6dTp04MGDCAyy+/vNqmDaqzYsUKevToQd++fTl+vO4qRiQkJHD48E9vmDzV+Pqmib4euJ0OnvllX4pKPfzhvY00tHsXlGoojDGMGzeO4cOH8/3337N27Voee+wxDh06dEbre+utt/jjH//I+vXrCQ0NreVoGw9N9PWkU1wEfxzdnWU7svjP6n3+DkepBmnp0qW43W6mTJlSOa5Pnz4MHToUYwz33XcfPXv2pFevXrz99tuA1Xzx8OHDufbaazn33HO54YYbMMYwa9Ys3nnnHR566KHKcadafsyYMZXvN3XqVObMmQNYJfJp06bRv39/evXqVdlsQXZ2NiNHjqRHjx5MnjzZp8LbM888Q8+ePenZsyfPPfccAAUFBVxxxRX06dOHnj17Vsb0wAMPkJSURO/evWvlASfaBEI9uvH8jny+9RB/+2gbgzvFkhBbcwNNSvnNJw/AwU21u87WvWD046ecvHnz5somiav673//y/r169mwYQOHDx/mvPPO46KLLgLgu+++Y8uWLbRt25bBgwfz1VdfMXnyZFauXMmYMWO49tpree+99065fHViY2NZt24d//jHP3jqqaeYNWsWjzzyCEOGDOHhhx/m448/5tVXX612HWvXruW1117j22+/xRjDoEGDGDZsGLt376Zt27Z8/PHHgNUiZnZ2Nu+//z7bt29HRCqbOT4bWqKvRw6H8OQveuN2Cr9/dwMeX557qJQCrGaJJ0yYgNPppFWrVgwbNow1a9YAVvPF8fHxOBwO+vbtyw8//HBay1fn6quvBmDAgAGV612+fHllE8lXXHEFMTExNcY+btw4wsPDiYiI4Oqrr2bFihX06tWLzz//nPvvv58VK1YQHR1NdHQ0ISEh3Hbbbfz3v//1+SEo1dESfT1rEx3KX6/qyW/mreeVL7/nrhGd/R2SUidXTcm7rvTo0YP58+ef9nLBwSee+uZ0Oikr8735kVM1a1x13ae7Xl907dqVdevWsXDhQh588EEuueQSHn74YVavXs3ixYuZP38+L774IkuWLDmr96mxRC8is0UkU0ROWhFcLDNEJFVENopIf69pHhFZb3cLzirSAHJln7Zc3qs1zy/epU0kKOXl4osvpri4mJkzZ1aO27hxIytWrGDo0KG8/fbbeDwesrKyWL58OQMHDvR53adavmPHjmzdupXi4mJycnJYvHhxjeu66KKL+M9//gPAJ598wtGjR2t87w8++IDCwkIKCgp4//33GTp0KPv37ycsLIyJEydy3333sW7dOvLz88nNzeXyyy/n2WefZcOGDT5v46n4UqKfA7wIvHGK6aOBLnY3CHjZ7gMcN8b0PbsQA4+I8OcrkvhiWybPfr6TJ3/Rx98hKdUgiAjvv/8+v/3tb3niiScICQkhISGB5557jiFDhrBq1Sr69OmDiPD3v/+d1q1b+9yu+7hx4066PMB1111Hz549SUxMpF+/fjWua9q0aUyYMIEePXpw4YUX0qFDh2rn79+/P5MmTao8ME2ePJl+/fqxaNEi7rvvPhwOB263m5dffpm8vDzGjh1LUVERxhieeeYZn7avOj41UywiCcBHxpieJ5n2T2CZMWauPbwDGG6MOSAi+caYiNMJqLE2U3wmHv14K6+u3MMnv7mIbq3r5yHBSlVHmyluHPzRTHE7IM1rON0eBxAiIiki8o2IXHWqFYjI7fZ8KVlZWbUQUuNw5/DOhAe7eHJR/T1pRinV9NR1rZuO9hHmeuA5Eel0spmMMTONMcnGmOS4uLg6DqnhiAkP4o7hnfhiWyar9xzxdzhKqQBVG4k+A2jvNRxvj8MYU9HfDSwDaj751cTccmEiraKCefyTbXrHrGoQdD9s2M7k+6mNRL8AuMmufXM+kGufn48RkWAAEYkFBgNba+H9AkpokJN7Lu3Kun05fLb1zG7zVqq2hISEkJ2drcm+gTLGkJ2dTUhIyGktV2OtGxGZCwwHYkUkHZgGuO03fQVYCFwOpAKFwC32ot2Bf4pIOdYB5XFjjCb6k7h2QDz/WrGbv3+6nUvObYnLqfexKf+Ij48nPT2dpnStrLEJCQkhPj7+tJbRh4M3EIu2HOT/3lzL41f3YvzA6qtqKaVUVfpw8EZgZFIr+ndoxrNf7OR4icff4SilAogm+gZCRHhgdHcOHSvmta/3+DscpVQA0UTfgAxMbM6l3Vvy8rLvOZxf7O9wlFIBQhN9A/PA6O4Ul5Yz/UO9bq2Uqh2a6BuYzi0juHNEJxZs2M/SHZn+DkcpFQA00TdAdwzvROeWETz4/mYKimu3WVSlVNOjib4BCnY5eeKaXuzPPc5Tn+3wdzhKqUZOE30DNaBjcyYO6sicr39gfVqOv8NRSjVimugbsD+M6karyBAeeG8jpZ7ymhdQSqmT0ETfgEWGuPnrVT3ZfjCPmct3+zscpVQjpYm+gftZUqvKxw7uzsr3dzhKqUZIE30j8JcrexDicvCn9zdpq4JKqdOmib4RaBkZwp8u7843u48w/aOtlJdrsldK+c6Xh4OrBuCX57Vn56F8Zn+1h+z8Ep76RR+CXHqcVkrVTBN9IyEiPDSmOy2jgnn8k+0cKSjhlRsHEBGsX6FSqno1FglFZLaIZIrI5lNMFxGZISKpIrJRRPp7TbtZRHbZ3c21GXhTJCJMGdaJp3/Rh1W7s5kw8xuy8rTxM6VU9Xz57z8HGFXN9NFAF7u7HXgZQESaYz2NahAwEJgmIjFnE6yyXDMgnlk3JZOamc+1r3zN3uwCf4eklGrAakz0xpjlwJFqZhkLvGEs3wDNRKQNcBnwuTHmiDHmKPA51R8w1GkYcW5L3vrVIHKPl3LNy1+z7cAxf4eklGqgauNqXjsgzWs43R53qvE/ISK3i0iKiKTosyp9179DDPOnXIjL4WDy6ykcLSjxd0hKqQaoQVTbMMbMNMYkG2OS4+Li/B1Oo9K5ZQT/vHEAWXnF/Pbt9Xi06qVSqoraSPQZQHuv4Xh73KnGq1rWp30zpl2ZxJc7s5ixeJe/w1FKNTC1kegXADfZtW/OB3KNMQeARcBIEYmxL8KOtMepOnD9wA5c0z+eGUt26QNLlFI/4kv1yrnAKqCbiKSLyG0iMkVEptizLAR2A6nAv4A7AYwxR4C/Amvsbro9TtUBEeFvV/WkW6tIfjtvPWlHCv0dklKqgZCG1nZKcnKySUlJ8XcYjdbe7ALGvLCShBbhvDvlAkLcTn+HpJSqByKy1hiTfLJpDeJirKo9HVuE8+x1fdmUkcsjH27xdzhKqQZAE30AujSpFXeN6MTc1Wm8syat5gWUUgFNE32A+t3PujGkcywPfrCZdfuO+jscpZQfaaIPUE6H8MKEfrSODuH/3lzLgdzj/g5JKeUnmugDWEx4ELNuTqawuIzb31hLUanH3yEppfxAE32A69oqkufH92Pz/lz+MH+jPqFKqSZIE30TcGlSK+4d2Y0FG/bz8pff+zscpVQ900TfRNw5vBM/79OWJxft4Iuth/wdjlKqHmmibyJEhL9f05uebaP5zbzv2Hkoz98hKaXqid4Z28QcyD3Oz1/4ioLiMto3D6VVVIjdBdMqKoROcRFc2KkFIuLvUJVSp6G6O2P1gaNNTJvoUN6aPIi3vt3LoWNFHDxWTGrmYTLziiubOP71JV343c+6+jlSpVRt0UTfBHVrHcn0sT1/NK683JBdUMKTi7YzY/EuokPd3DYk0U8RKqVqkyZ6BYDDIcRFBvPY1b3JKyrjrx9tJTrUzbUD4v0dmlLqLOnFWPUjTofw3Pi+DO0Sy/3vbWTRloP+DkkpdZY00aufCHY5eWXiAHrHR3P3f77jq9TD/g5JKXUWfEr0IjJKRHaISKqIPHCS6R1FZLGIbBSRZSIS7zXNIyLr7W5BbQav6k54sIs5kwZyTlw4v3ojhfVpOf4OSSl1hnx5wpQTeAkYDSQBE0QkqcpsTwFvGGN6A9OBx7ymHTfG9LW7K2spblUPosPcvHHrQGIjgpn02mp2HNS690o1Rr6U6AcCqcaY3caYEmAeMLbKPEnAEvv10pNMV41Uy6gQ3po8iGCXg4mvfsve7AJ/h6SUOk2+JPp2gPfTK9Ltcd42AFfbr8cBkSLSwh4OEZEUEflGRK46m2CVf7RvHsa/bxtEmaecG2Z9q00eK9XI1NbF2HuBYSLyHTAMyAAq2sTtaN+tdT3wnIh0qrqwiNxuHwxSsrKyaikkVZu6tIrkjVsHkVNYysRZ33I4v9jfISmlfORLos8A2nsNx9vjKhlj9htjrjbG9AP+bI/LsfsZdn83sAzoV/UNjDEzjTHJxpjkuLi4M9gMVR96xUcze9J5ZOQc56ZXV5N7vNTfISmlfOBLol8DdBGRRBEJAsYDP6o9IyKxIlKxrj8Cs+3xMSISXDEPMBjYWlvBq/o3MLE5/7wxmV2Zedw6Zw2FJWX+DkkpVYMaE70xpgyYCiwCtgHvGGO2iMh0EamoRTMc2CEiO4FWwKP2+O5AiohswLpI+7gxRhN9Izesaxwzxvfju31H9clVSjUC2nqlOmPz16Zz77sb6Nu+GU9c05turSP9HZJSTVZ1rVfqnbHqjF07IJ4Xr+/HviOFXDFjBc98tkNL90o1QJro1VkZ07stX/xuGFf2acuMJalcPmMFq/cc8XdYSikvmujVWWseHsQzv+zLG7cOpKSsnOv+uYo/vb+JY0VaK0ephkATvao1F3WN47N7LuJXQxOZt3oflz+/Qh9ZqFQDoIle1aqwIBd/viKJ+XdcSHFZOdf842uW79Sb4JTyJ030qk707xDDB3cNpl1MKLfMWcOb3+z1d0hKNVma6FWdadcslPl3XMiwrnE89MFmpn+4tfK5tEqp+qOJXtWpiGAX/7opmVsGJzD7qz3c/kYK+cV6N61S9UmfGavqnNMhTPt5DxJjw/nLgi1c9uxy+neMITE2nE5x4STGhpMQG05UiNvfoSoVkDTRq3pz0wUJJLQIZ9bKPaxPO8pHG/fjfWN266gQxvVvx43nd6Rts1D/BapUgNEmEJTfFJV6SDtSyO7DBew5XMDavUdZvO0QIsKoHq2ZNDiB5I4xiIi/Q1WqwauuCQQt0Su/CXE76dIqki6tTrSRk360kDe/2cu81Wl8vOkAPdpGMenCBK7q1w63Uy8pKXUmtESvGqTjJR7e/y6DOV/vYeehfIZ2ieWViQMID9ayiVIno42aqUYnNMjJ9YM6sOi3F/H41b34+vtsbpj1LUcLSvwdmlKNjiZ61aCJCOMHduDlG/qz9cAxrvvnKg7mFvk7LKUaFU30qlEY2aM1r98ykAO5RVzz8tfszsr3d0hKNRo+JXoRGSUiO0QkVUQeOMn0jiKyWEQ2isgyEYn3mnaziOyyu5trM3jVtFzQqQXzbj+folIPv3hlFZszcv0dklKNQo2JXkScwEvAaCAJmCAiSVVmewp4wxjTG5gOPGYv2xyYBgwCBgLTRCSm9sJXTU3PdtG8O+UCQtxOxs/8Rtu+V8oHvpToBwKpxpjdxpgSYB4wtso8ScAS+/VSr+mXAZ8bY44YY44CnwOjzj5s1ZSdExfB/DsuoFVUMJNfX8OewwX+DkmpBs2XRN8OSPMaTrfHedsAXG2/HgdEikgLH5dFRG4XkRQRScnK0iZtVc3aRIcy55aBuJwObnt9DbnH9SEnSp1KbV2MvRcYJiLfAcOADMDnh4caY2YaY5KNMclxcXG1FJIKdO2bh/GPG/qzL7uQX8/9TlvGVOoUfEn0GUB7r+F4e1wlY8x+Y8zVxph+wJ/tcTm+LKvU2Tj/nBZMH9uTL3dm8djCbf4OR6kGyZdEvwboIiKJIhIEjAcWeM8gIrEiUrGuPwKz7deLgJEiEmNfhB1pj1Oq1lw/qAOTLkxg1so9vJuSVvMCSjUxNSZ6Y0wZMBUrQW8D3jHGbBGR6SJypT3bcGCHiOwEWgGP2sseAf6KdbBYA0y3xylVqx68ojtDOsfy5/c3s3av7mJKedO2blTAyCks4aqXviK/uIz/TR1Ci/AgCorLKCzxUFBSRkGxh2CXgx5to7RFTBVwqmvrRhO9CiipmfmMe+kr8qp5ilXXVhHceH5HrurXjkh92IkKEJroVZOyKT2Xz7YeJCzIRXiwk1C3k/BgF2FBTg7mFvHWt/vYlJFLeJCTq/vHM/H8jnRrHVnzipVqwDTRK1XF+rQc3ly1lw837qekrJyBic25f9S5DOioN26rxkkTvVKncLSghHfXpjF75Q8cPFbEhIEduH9UN5qFBfk7NKVOi7ZHr9QpxIQHcftFnVj8+2H8amgi76SkccnTX/Le2nQaWiFIqTOliV4pIDzYxZ+vSOLDqUPo0CKM37+7gQn/+obUzDx/h6bUWdNEr5SXpLZRvDflQh67uhfbDuQx+vkV/P3T7RSWnLoWj1INnSZ6papwOIQJAzuw+PfDuLJPO/6x7HsuffpLPt18QE/nqEZJE71SpxAbEczT1/Xh3SkXEBXqZsq/13Hza9ossmp8NNErVYPzEprz0d1DmPbzJL7be5TLnl3OU4t2cLzE5wZalfIrTfRK+cDldHDL4EQW3zuMMb3b8OLSVC56cimzVuzW8/eqwdN69EqdgZQfjvDsFzv5KjWb5uFBTB6ayE0XJBAR7PJ3aKqJ0humlKoja/ceYcbiVL7cmUV0qJtbBydyVb+25BeXcaSg5EddkNPB5KHnEBrk9HfYKgBpoleqjm1Iy+GFJbv4YlvmSaeLgDFwwTkteHVSMmFBWvJXtUsTvVL1ZOv+Y2xIzyEmzE3z8GCahwfRPDyI6FA3CzZk8Pt3NpCc0JzXJp1HuJ7mUbWoukTv054mIqOA5wEnMMsY83iV6R2A14Fm9jwPGGMWikgC1sNKdtizfmOMmXImG6FUY5DUNoqktlEnnTauXzxOh4N73l7PzbNX89ot52kzyape1FjrRkScwEvAaCAJmCAiSVVmexDryVP9sB41+A+vad8bY/ranSZ51aRd2actL0zox/q0HG6avZpjRaX+Dkk1Ab5UrxwIpBpjdhtjSoB5wNgq8xigohgTDeyvvRCVCiyX92rDSzf0Z3NGLjfO+pbcQk32qm75kujbAd5PXE63x3n7CzBRRNKBhcDdXtMSReQ7EflSRIae7A1E5HYRSRGRlKysLN+jV6qRuqxHa16+YQDbDuRx/axveHvNPpbtyGTbgWMcKSjRphZUrarxYqyIXAuMMsZMtodvBAYZY6Z6zfM7e11Pi8gFwKtAT8ANRBhjskVkAPAB0MMYc+xU76cXY1VTsnRHJlPfWkdBlbtsg5wO4iKDSU6IYUzvtlzUNZZgl1bLVKd2thdjM4D2XsPx9jhvtwGjAIwxq0QkBIg1xmQCxfb4tSLyPdAV0EyuFDCiW0u+e3gkmXlFHDpWzKFjRXZXTEbOcb7cmcX/1u8nMsTFyKTWjOnThiGdY3E79aZ25TtfEv0aoIuIJGIl+PHA9VXm2QdcAswRke5ACJAlInHAEWOMR0TOAboAu2steqUCQJDLQXxMGPExYT+ZVuop56vUw3y08QCLthzkvXXpNAtzM6xrHH3bN6Nv+2YktY3S0r6qlk/16EXkcuA5rKqTs40xj4rIdCDFGLPAroXzLyAC68LsH4wxn4nINcB0oBQoB6YZYz6s7r301I1SJ1dc5mH5zsN8tHE/q77PJjOvGAC3U0hqE0Xf9s3o0S6ajs3D6NAijFaRITgc4ueoVX3RG6aUCjDGGA4eK2L9vhzWp+ewfl8OmzJyKfQ61x/kdBAfE0r75mF0aRnB1Is767NwA9hZ3zCllGpYRIQ20aG06RXK6F5tAPCUG/YdKSTtSKHVP3ri9derDvPFtkPMuvk8OreM8HP0qr5polcqQDgdQmJsOImx4T+ZtnbvEf7vzbWM+8dXvDChH8O7tfRDhMpf9NK9Uk3AgI7N+d/UIcTHhHHrnDXMXrlH6+o3IZrolWoi2jULZf6UC/hZUiumf7SVP/53EyVl5f4OS9UDTfRKNSHhwS5evmEAU0d0Zt6aNCa++i27s/L9HZaqY5rolWpiHA7h3su68fz4vmxIy+Hip79kwsxv+HDDfi3hByi9GKtUEzW2bzsu6NSCd1PSmbt6H3fP/Y4W4UFcOyCeCQM7kHCSi7qqcdJ69EopyssNK1IP859v9/LFtkw85YYOzcNo1yyUdjGhlf34mFC6t44iJlzr4zc0Wo9eKVUth0MY1jWOYV3jyDxWxHvrMth64BgZRwtZsSuLzLxiKsqEIW4Hky5MZMqwc/QGrEZCS/RKqRoVl3k4mFtE2pHjzF+bxv827CciyMXkoedw29BEIvSxiH6nTSAopWrV9oPHeOaznXy29RAxYW7uHN6ZGy/oSIjbt8bVVu85wpvf7CUi2EXv+Gh6tYumW+tIbZXzLGiiV0rVifVpOTz92Q5W7DpMbEQQY/u2Y1y/dvRoG4XIjxtUM8aw6vtsZizZxTe7jxAT5qas3JBXVAZYrXh2bxNF73bRxEYE4zEGT3k5ZeUGj8fgMYakNlH8Irn9yUJp8jTRK6Xq1De7s5m9cg9Ld2RS6jF0bRXBuH7xjO3bljbRISzfdZgXFu8iZe9RWkYGM2VYJyYM7ECI28He7EI2ZeSyKSOXjek5bM44Rn6xlfxdDsFpdwIUlHi459Ku/ObSLv7d4AZIE71Sql4cLSjh400HeP+7DNbuPYqIdUdu+tHjtIkO4Y7hnbguuX21p3iMMRjDT5pYLi83/OG9jcxfm859l3XjrhGd63pzGhWtdaOUqhcx4UFMPL8jE8/vyN7sAj74bj9rfjjCncM7c82Adj49IEVEkJM0o+9wCE9c0xtPueHJRTtwOoQpwzrVwVYEHp8SvYiMAp7HevDILGPM41WmdwBeB5rZ8zxgjFloT/sj1qMGPcCvjTGLai16pVSD1bFFeK2fYnE6hCev7U1ZueHxT7bjcgiTh55Tq+8RiGpM9CLiBF4CfgakA2tEZIExZqvXbA8C7xhjXrafNrUQSLBfjwd6AG2BL0SkqzHmx09CVkopH7mcDp69rg+e8nL+9vE2nA7hlsGJ/g6rQfOlLtNAINUYs9sYUwLMA8ZWmccAUfbraGC//XosMM8YU2yM2QOk2utTSqkz5nI6eH58Py7r0YpHPtzKa1/toby8YV1vbEh8SfTtgDSv4XR7nLe/ABNFJB2rNH/3aSyLiNwuIikikpKVleVj6EqppsztdPDChP5c2r0lj3y4lSFPLOGxhdvYsj9X29qvorbuTpgAzDHGxAOXA2+KiM/rNsbMNMYkG2OS4+LiaikkpVSgC3I5eHniAJ4f35dz20Tx6so9XDFjJZc+8yUzFu9iz+ECTfr4djE2A/C+QyHeHuftNmAUgDFmlYiEALE+LquUUmfM7XQwtm87xvZtx5GCEj7ZfID/rd/PM5/v5JnPdxIR7CIxNpwE+zGL59ivo0PduJ1CkNOB2+nA7XLgdgr5RWUcyC2yu+Psz7H6kSEupo7oQuvokLOKt6SsHLdTfnJDWV2qsR69iLiAncAlWEl6DXC9MWaL1zyfAG8bY+aISHdgMdYpmiTgP1jn5dva47tUdzFW69ErpWrD/pzjLN52iNTMfHYfLuCH7AIyjh7ndE/lu51Cq6gQMvOKcTmEX1/ShVsHJxLk8v2EyLGiUpZsy2ThpgN8uTOLS7q3ZMb4frhqscmHs6pHb4wpE5GpwCKsqpOzjTFbRGQ6kGKMWQD8HviXiNyDdWF2krGOIFtE5B1gK1AG3KU1bpRS9aFts1BuvCDhR+OKyzykHSnkh8OFFJSUUVJWTqnHUFLmsfqecsKCnLSJDqVNdAhtmoUQGx6MwyHsyy5k+kdbefyT7byzJo1pV/ZgWNdTn2rOLSzl822H+GTTAVbsOkyJp5zWUSEM7xbHwk0HCXJu4Onr+uJ01H3JXu+MVUqp07B0RybTP9zKnsMFjExqxb2XdSO/uIzUQ/mkZuWz61AeqVn5pB89jjHWncGje7ZmdK829GvfDIdDeGlpKk8u2sGEge35f+N61cppHL0zVimlasmIbi25sFMLXl25hxcWp/LZ1kOV04JcDjrFRdC3fQy/GNCeYV3j6B0f/ZNEfteIzhSWlPHS0u8JcTt5eExSnZ6z10SvlFKnKdjl5M7hnRnXrx2fbz1E2+hQurSKID4mzOdTMfeO7EZhiYfXvvqB8CAX917Wrc7i1USvlFJnqE10KDdVuQ7gKxHh4TFJHC/x8OLSVEKDnHXWUJsmeqWU8hMR4dFxvThe6uHJRTsIdTu5dUjtN+egj3NRSik/cjqEp3/Rh8t6tGLpDuvB7LVNS/RKKeVnLqeDGRP6YQx1Ut1SE71SSjUAvrTVf6b01I1SSgU4TfRKKRXgNNErpVSA00SvlFIBThO9UkoFOE30SikV4DTRK6VUgNNEr5RSAU4TvVJKBTifEr2IjBKRHSKSKiIPnGT6syKy3u52ikiO1zSP17QFtRi7UkopH9TYBIKIOIGXgJ8B6cAaEVlgjNlaMY8x5h6v+e8G+nmt4rgxpm+tRayUUuq0+FKiHwikGmN2G2NKgHnA2GrmnwDMrY3glFJKnT1fEn07IM1rON0e9xMi0hFIBJZ4jQ4RkRQR+UZErjrFcrfb86RkZWX5FrlSSimf1PbF2PHAfGOMx2tcR/uBtdcDz4lIp6oLGWNmGmOSjTHJcXGnfqq6Ukqp0+dLos8A2nsNx9vjTmY8VU7bGGMy7P5uYBk/Pn+vlFKqjvmS6NcAXUQkUUSCsJL5T2rPiMi5QAywymtcjIgE269jgcHA1qrLKqWUqjs11roxxpSJyFRgEeAEZhtjtojIdCDFGFOR9McD84wx3s/B6g78U0TKsQ4qj3vX1lFKKVX35Md52f+Sk5NNSkqKv8NQSqlGRUTW2tdDf0LvjFVKqQCniV4ppQKcJnqllApwmuiVUirAaaJXSqkAp4leKaUCnCZ6pZQKcJrolVIqwGmiV0qpAKeJXimlApwmeqWUCnCBleg9pf6OQCmlGpzASfQ5afDyYNi5yN+RKKVUgxI4iT6sBbhDYP5tkLnd39EopVSDETiJPigMxv8H3KEwdzwUHvF3REop1SD4lOhFZJSI7BCRVBF54CTTnxWR9Xa3U0RyvKbdLCK77O7mWoz9p6LjYfxbcCwD3r1Zz9krpRQ+JHoRcQIvAaOBJGCCiCR5z2OMuccY09cY0xd4AfivvWxzYBowCBgITBORmFrdgqraD4SfPw97lsOiP9XpWymlVGPgS4l+IJBqjNltjCkB5gFjq5l/AiceEH4Z8Lkx5ogx5ijwOTDqbAL2Sd/r4YKpsHompLxW52+nlFINWY3PjAXaAWlew+lYJfSfEJGOQCKwpJpl251kuduB2wE6dOjgQ0g++Nl0yNoOC++F2K6QMPjEtLISyNwKBzYABrqMhKi2tfO+SinVwPiS6E/HeGC+McZzOgsZY2YCM8F6ZmytROJwwjWvwqxL4Z0b4aI/QOYWK7kf2grlVc7ft+0H3S63ulY9QKRWwjgpT5kVS3EetO1vXUhuCoyBvANQmA0xiRAc4e+IlGoSfEn0GUB7r+F4e9zJjAfuqrLs8CrLLvM9vLMU2gwmzINZF8On90NoDLTpAxfcZfXb9oXSItj5CWxfCEsftbpmHSDhIqu6pjitg4Y4TvQ9pXZXcqJfXmpV8YxuD83aW/3o9hDRCopyIH0NpK2GtG8hYx2UFlgxOlzQpi90vAA6XAgdzoew5lZSLD4GeQet5Jh3EAqyrFpFIc2sbQuJsfvNrAOTp9SKw1NiHUwqDmYOl9U53fZrN2Cg6BgU51oHnKJj1vuVFILDYc0nzhPLiljTC7Oh8Kjdz4bjR62YIttAVBuIbAuRra1/SJ4SyNxm/Xuq6Bflnvh+otpBbBdo0cX619WsgxVLQZZXd9h6H2eQdWAIjoQgux8cCe4wcAXbXciJPkBJPpQU2F2+tW2eEmuZ4AgICoegSLsfZn3mphzKPWA8J/qm/MS0yn45lNufsafsxD7gKbOWkYp9xmH1K4bB+uzBWlcFEUDseR3WsDis96jcx7xeg/19uq1+xWuH04q7vMzqKrajvMx+P+/3tl97f89O14nXxtjLl9mfhb3NlfuU13IOlx2vx+t9y6Dc/qxcQfZ3FWLtL+5QcIWe2Cer9j2lUFp44vsrLbS+w/Jy63dZdV3itPbFiv2yoivKtaYHR0FIlL3fRFldeZn1OywpPPFepYXWdgRF2PuIvZ8FR1jvV/H947UfmGrKphWfXcW+UjFc8Z1X7BcVXXgcdB3pS3Y7LWKqCxIQERewE7gEK3GvAa43xmypMt+5wKdAorFXal+MXQv0t2dbBwwwxpyy7mNycrJJSUk5s605leM51hferEP1JfW8g7DzU9jxiZWMK3fYcq8ffrn9wwry6uydsyDLSureHO4TCVec0LoXtB9kXTQOjoR9q2DvKti/7sQPOCoejh+xdrqGKCjCOhiFNrf6JYWQt9/6/Cq2wVtINLRMgpbdrX5YCziyGw7vgsM7ITvVOoh4c7ggLNba8cOaW99FcZ71Yy/Og+J8KDt+enE7XNb31VA/V1+I09rfwEqGPv95Fq+DiZwYB3ayOq0/4Q2fw23tZyHR1n5SUZipbjtd9gHElNsHlbL6i7dCu2T41eIzWlRE1hpjkk82rcYSvTGmTESmAosAJzDbGLNFRKYDKcaYBfas44F5xuvIYYw5IiJ/xTo4AEyvLsnXmdBmVleTyNYwYJLVnaniPOsu3dw0yNln9UOireTetp9VevTW9TKrX1oEGWth39eQtdNKcBUl48jWVok5PBZKj9sHrpwTB7CiHKtU4bQTWUUpr6Ik7im1SxX2P5GKHTgk2i7dRJ4o7QRFeJVWvUtzHmvesOZWqflkjLFKUXkH4NgBqzTbMsmKvboDrDGQfwhy062YwlpY/1IcNdQV8JRan4enBMqKoKzY7hdZhdXgCOuHGxRubZcryFquvPxECbGkwPrOSgsBsUupTq9/cna/srTt1a/4d+Rdona6rekVpWHvfwimnMrkWjXZUvUfg13iFodXYcL908+k3P6uKv5RlJd7lbSdXv/MavgsjTnxL6Din0PFNorX+ir+lVTuI2Ve+4rnxOfnvZzIie+mtNDa18uOW/3KuMtO/Av1lFrb6w6zvrcg+zt0h1vrLj1udWV2v7TQ2u7QGGv/DGth7ctV9zljrPmLj1nfucNprTMozHovh/PH85YV24WLioJFsf3d8+NSOKfat82JfaTiM3G67VK8nCg4VnYe+9927auxRF/f6qREr5RSAa66En3g3BmrlFLqpDTRK6VUgNNEr5RSAU4TvVJKBThN9EopFeA00SulVIDTRK+UUgFOE71SSgW4BnfDlIhkAXvPYhWxwOFaCqcx0e1uWnS7mxZftrujMSbuZBMaXKI/WyKScqq7wwKZbnfTotvdtJztduupG6WUCnCa6JVSKsAFYqKf6e8A/ES3u2nR7W5azmq7A+4cvVJKqR8LxBK9UkopL5rolVIqwAVMoheRUSKyQ0RSReQBf8dTl0Rktohkishmr3HNReRzEdll92P8GWNtE5H2IrJURLaKyBYR+Y09PtC3O0REVovIBnu7H7HHJ4rIt/b+/raIBPk71rogIk4R+U5EPrKHm8p2/yAim0RkvYik2OPOeF8PiEQvIk7gJWA0kARMEJEk/0ZVp+YAo6qMewBYbIzpAiy2hwNJGfB7Y0wScD5wl/0dB/p2FwMXG2P6AH2BUSJyPvAE8KwxpjNwFLjNfyHWqd8A27yGm8p2A4wwxvT1qj9/xvt6QCR6YCCQaozZbYwpAeYBY/0cU50xxiwHqj57dyzwuv36deCq+oyprhljDhhj1tmv87B+/O0I/O02xph8e9Btdwa4GJhvjw+47QYQkXjgCmCWPSw0ge2uxhnv64GS6NsBaV7D6fa4pqSVMeaA/fog0MqfwdQlEUkA+gHf0gS22z59sR7IBD4HvgdyjDH2U94Ddn9/DvgDUG4Pt6BpbDdYB/PPRGStiNxujzvjfd1V29Ep/zPGGBEJyHqzIhIBvAf81hhzzCrkWQJ1u40xHqCviDQD3gfO9W9EdU9ExgCZxpi1IjLcz+H4wxBjTIaItAQ+F5Ht3hNPd18PlBJ9BtDeazjeHteUHBKRNgB2P9PP8dQ6EXFjJfm3jDH/tUcH/HZXMMbkAEuBC4BmIlJRUAvE/X0wcKWI/IB1KvZi4HkCf7sBMMZk2P1MrIP7QM5iXw+URL8G6GJfkQ8CxgML/BxTfVsA3Gy/vhn4nx9jqXX2+dlXgW3GmGe8JgX6dsfZJXlEJBT4Gdb1iaXAtfZsAbfdxpg/GmPijTEJWL/nJcaYGwjw7QYQkXARiax4DYwENnMW+3rA3BkrIpdjndNzArONMY/6N6K6IyJzgeFYTZceAqYBHwDvAB2wmnm+zhhT9YJtoyUiQ4AVwCZOnLP9E9Z5+kDe7t5YF96cWAWzd4wx00XkHKySbnPgO2CiMabYf5HWHfvUzb3GmDFNYbvtbXzfHnQB/zHGPCoiLTjDfT1gEr1SSqmTC5RTN0oppU5BE71SSgU4TfRKKRXgNNErpVSA00SvlFIBThO9UkoFOE30SikV4P4/4lGXrI/A9dIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.plot(range(epochs), loss, label = 'train loss')\n",
    "plt.plot(range(epochs), emotion_loss, label = 'Arousal loss')\n",
    "plt.plot(range(epochs), confound_loss, label = 'Confound loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-owner",
   "metadata": {},
   "source": [
    "## Train all folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quality-costa",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = []\n",
    "uar = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 0, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 1, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 2, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-possibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 3, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MasterNet(acoustic_modality = True, lexical_modality = True, visual_modality = False)\n",
    "best_acc, best_uar = train_one_folder(model, folder = 4, verbose = True, epochs = 10)\n",
    "acc.append(best_acc)\n",
    "uar.append(best_uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "listed-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(5),acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(5),uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acc)\n",
    "print(uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-shakespeare",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-process",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([acc,uar]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(uar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-terrorism",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
